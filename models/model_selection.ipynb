{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Model Selection\n",
    "\n",
    "In this notebook we will test different models to find the one that gives us the best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def f1_scores(Z, y_test):\n",
    "    averages = ['macro', 'micro', 'weighted']\n",
    "    for avg in averages:\n",
    "        score = f1_score(Z, y_test, average=avg)\n",
    "        print(\"f1 score ({}): {}\".format(avg, score))\n",
    "\n",
    "def test_model(X, y, model_name, model):\n",
    "    print(\"MODEL: {}\".format(model_name))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    model.fit(X_train, y_train)\n",
    "    Z = model.predict(X_test)\n",
    "    f1_scores(Z, y_test)\n",
    "    \n",
    "def testModelKFold(X, y, model_name, model, k):\n",
    "    print(\"CROSS VALIDATION FOR: {}\".format(model_name))\n",
    "    skf = StratifiedKFold(n_splits=5)\n",
    "    skf.get_n_splits(X, y)\n",
    "    f1_scores = []\n",
    "    for train_index, test_index in skf.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(X_train, y_train)\n",
    "        Z = model.predict(X_test)\n",
    "        f1_scores.append(f1_score(Z, y_test))\n",
    "    print(\"f1 scores: {}\".format(f1_scores))\n",
    "    print(\"MEAN: {}\".format(np.mean(f1_scores)))\n",
    "    return np.mean(f1_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL: Logistic Regression\n",
      "f1 score (macro): 0.8130113705517454\n",
      "f1 score (micro): 0.8479743281187325\n",
      "f1 score (weighted): 0.8515095436797728\n",
      "CROSS VALIDATION FOR: Logistic Regression\n",
      "f1 scores: [0.89928057553956831, 0.87277556440903059, 0.88527349228611507, 0.90554298642533926, 0.86995768688293373]\n",
      "MEAN: 0.8865660611085975\n",
      "\n",
      "MODEL: SVC\n",
      "f1 score (macro): 0.8272403060758199\n",
      "f1 score (micro): 0.8616125150421179\n",
      "f1 score (weighted): 0.8696182723463185\n",
      "CROSS VALIDATION FOR: SVC\n",
      "f1 scores: [0.92620137299771166, 0.87811271297509819, 0.89311939080772362, 0.89950027762354245, 0.88787061994609162]\n",
      "MEAN: 0.8969608748700335\n",
      "\n",
      "MODEL: Random Forest\n",
      "f1 score (macro): 0.841896382804318\n",
      "f1 score (micro): 0.8712394705174489\n",
      "f1 score (weighted): 0.8748732048431905\n",
      "CROSS VALIDATION FOR: Random Forest\n",
      "f1 scores: [0.90597279716144297, 0.89113785557986869, 0.89020270270270285, 0.87242306543172987, 0.87429854096520754]\n",
      "MEAN: 0.8868069923681903\n",
      "\n",
      "MODEL: K-Nearest Neighbors\n",
      "f1 score (macro): 0.80041075844836\n",
      "f1 score (micro): 0.8311271560369033\n",
      "f1 score (weighted): 0.8323520430573055\n",
      "CROSS VALIDATION FOR: K-Nearest Neighbors\n",
      "f1 scores: [0.87872404453806807, 0.8649986252405828, 0.86329695577254451, 0.83328290468986388, 0.86333808844507853]\n",
      "MEAN: 0.8607281237372275\n",
      "\n",
      "MODEL: GaussianNB\n",
      "f1 score (macro): 0.7491722020284054\n",
      "f1 score (micro): 0.7765744083433616\n",
      "f1 score (weighted): 0.7726170508779734\n",
      "CROSS VALIDATION FOR: GaussianNB\n",
      "f1 scores: [0.78364565587734258, 0.82630200756473671, 0.88976157082748941, 0.90085959885386813, 0.79052369077306728]\n",
      "MEAN: 0.8382185047793008\n",
      "\n",
      "MODEL: Perceptron\n",
      "f1 score (macro): 0.47494002752834763\n",
      "f1 score (micro): 0.709987966305656\n",
      "f1 score (weighted): 0.8115884242543604\n",
      "CROSS VALIDATION FOR: Perceptron\n",
      "f1 scores: [0.81541389153187438, 0.81744518589132498, 0.84503572308450359, 0.88069073783359508, 0.87541345093715539]\n",
      "MEAN: 0.8467997978556907\n",
      "\n",
      "MODEL: SGDClassifier\n",
      "f1 score (macro): 0.6449864765255751\n",
      "f1 score (micro): 0.7677496991576414\n",
      "f1 score (weighted): 0.8150629466249794\n",
      "CROSS VALIDATION FOR: SGDClassifier\n",
      "f1 scores: [0.20671834625322996, 0.83382497541789569, 0.89296468655899264, 0.88414460575007114, 0.87845592070944178]\n",
      "MEAN: 0.7392217069379263\n",
      "\n",
      "MODEL: Decision Tree\n",
      "f1 score (macro): 0.8254664973733635\n",
      "f1 score (micro): 0.8467709586843161\n",
      "f1 score (weighted): 0.8461350046153324\n",
      "CROSS VALIDATION FOR: Decision Tree\n",
      "f1 scores: [0.87970615243342509, 0.86075222509331029, 0.85589264877479587, 0.83004694835680748, 0.84296555750145941]\n",
      "MEAN: 0.8538727064319597\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=1000),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors = 3),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"Perceptron\": Perceptron(),\n",
    "    \"SGDClassifier\": SGDClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier()   \n",
    "}\n",
    "\n",
    "dataset_path = \"data-all.csv\"\n",
    "data = pd.read_csv(dataset_path, sep=\";\")\n",
    "X = data.drop(\"diagnosis\", axis=1).values\n",
    "y = data[\"diagnosis\"]\n",
    "\n",
    "for model in models:\n",
    "    test_model(X, y, model, models[model])\n",
    "    testModelKFold(X, y, model, models[model], k=5)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the confusion matrix for the Random Forest model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[ 530  214]\n",
      " [ 110 1639]]\n",
      "\n",
      "Classfication Report\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.83      0.71      0.77       744\n",
      "        1.0       0.88      0.94      0.91      1749\n",
      "\n",
      "avg / total       0.87      0.87      0.87      2493\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=1000)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "model.fit(X_train, y_train)\n",
    "Z = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_matrix(y_test, Z))\n",
    "\n",
    "print(\"\\nClassfication Report\")\n",
    "print(classification_report(y_test, Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compare the performances of the random forest for different numbers of estimators and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CROSS VALIDATION FOR: Random Forest with 1 features and 10 estimators\n",
      "f1 scores: [0.88888888888888895, 0.88057633693543913, 0.88054998567745635, 0.85068702290076348, 0.86346863468634683]\n",
      "MEAN: 0.872834173817779\n",
      "CROSS VALIDATION FOR: Random Forest with 1 features and 33 estimators\n",
      "f1 scores: [0.90029673590504455, 0.88491189427312766, 0.88068181818181823, 0.85826060788444181, 0.86544428772919613]\n",
      "MEAN: 0.8779190687947256\n",
      "CROSS VALIDATION FOR: Random Forest with 1 features and 100 estimators\n",
      "f1 scores: [0.89994044073853496, 0.88619454395150177, 0.88373408769448381, 0.86180828545509514, 0.86753100338218714]\n",
      "MEAN: 0.8798416722443605\n",
      "CROSS VALIDATION FOR: Random Forest with 1 features and 333 estimators\n",
      "f1 scores: [0.89988081048867707, 0.88888888888888884, 0.88316831683168318, 0.863855421686747, 0.86802030456852786]\n",
      "MEAN: 0.8807627484929048\n",
      "CROSS VALIDATION FOR: Random Forest with 1 features and 1000 estimators\n",
      "f1 scores: [0.9009223445403155, 0.88895012400110229, 0.88493073225897656, 0.86616541353383458, 0.86770098730606493]\n",
      "MEAN: 0.8817339203280588\n",
      "CROSS VALIDATION FOR: Random Forest with 5 features and 10 estimators\n",
      "f1 scores: [0.9055704498063748, 0.88446655610834701, 0.87977044476327104, 0.84518313327177585, 0.86988427885972341]\n",
      "MEAN: 0.8769749725618985\n",
      "CROSS VALIDATION FOR: Random Forest with 5 features and 33 estimators\n",
      "f1 scores: [0.91235294117647059, 0.89270152505446632, 0.89670575097710781, 0.88052179069077985, 0.87646730016769137]\n",
      "MEAN: 0.891749861613303\n",
      "CROSS VALIDATION FOR: Random Forest with 5 features and 100 estimators\n",
      "f1 scores: [0.91027154663518306, 0.89082493874217272, 0.89473684210526327, 0.87589073634204262, 0.87734003911707181]\n",
      "MEAN: 0.8898128205883467\n",
      "CROSS VALIDATION FOR: Random Forest with 5 features and 333 estimators\n",
      "f1 scores: [0.91155660377358494, 0.8925754691324449, 0.89753639417693165, 0.88210900473933651, 0.87863534675615218]\n",
      "MEAN: 0.89248256371569\n",
      "CROSS VALIDATION FOR: Random Forest with 5 features and 1000 estimators\n",
      "f1 scores: [0.91224970553592455, 0.89275993467610226, 0.89633975970941604, 0.88257911860396332, 0.87901648505169039]\n",
      "MEAN: 0.8925890007154195\n",
      "CROSS VALIDATION FOR: Random Forest with 11 features and 10 estimators\n",
      "f1 scores: [0.90247539516850583, 0.88106459661768788, 0.87686139747995429, 0.84906240393482946, 0.87347170884276371]\n",
      "MEAN: 0.8765871004087483\n",
      "CROSS VALIDATION FOR: Random Forest with 11 features and 33 estimators\n",
      "f1 scores: [0.91108476585655018, 0.88992332968236587, 0.89164086687306521, 0.86744815148782695, 0.87507066139061618]\n",
      "MEAN: 0.8870335550580849\n",
      "CROSS VALIDATION FOR: Random Forest with 11 features and 100 estimators\n",
      "f1 scores: [0.91236352906462082, 0.88791449712249926, 0.89089371299689879, 0.88009520975900013, 0.87813115676892772]\n",
      "MEAN: 0.8898796211423893\n",
      "CROSS VALIDATION FOR: Random Forest with 11 features and 333 estimators\n",
      "f1 scores: [0.91524426133019421, 0.89010687859687587, 0.89164086687306521, 0.8827545265657466, 0.87840494243190115]\n",
      "MEAN: 0.8916302951595567\n",
      "CROSS VALIDATION FOR: Random Forest with 11 features and 1000 estimators\n",
      "f1 scores: [0.91428571428571426, 0.88791449712249926, 0.89245495495495486, 0.8812146472164335, 0.87977528089887636]\n",
      "MEAN: 0.8911290188956956\n"
     ]
    }
   ],
   "source": [
    "res = np.zeros([3,5])\n",
    "for i_f, n_f in enumerate([1,5,11]):\n",
    "    for i_e, n_e in enumerate([10,33,100,333,1000]):\n",
    "        model = RandomForestClassifier(n_estimators=n_e, max_features=n_f)\n",
    "        model_name = \"Random Forest with %i features and %i estimators\" % (n_f, n_e)\n",
    "        f1 = testModelKFold(X, y, model_name, model, k=5)\n",
    "        res[i_f, i_e] = f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.87283417,  0.87791907,  0.87984167,  0.88076275,  0.88173392],\n",
       "       [ 0.87697497,  0.89174986,  0.88981282,  0.89248256,  0.892589  ],\n",
       "       [ 0.8765871 ,  0.88703356,  0.88987962,  0.8916303 ,  0.89112902]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill as pickle\n",
    "\n",
    "def dump_model(model, path):\n",
    "    with open(path, 'wb') as file:\n",
    "        pickle.dump(model, file)\n",
    "        \n",
    "#Â Define path to save the model file\n",
    "filename = \"model_v2.pk\"\n",
    "dir_path = \"./\"\n",
    "\n",
    "# Dump model to file\n",
    "dump_model(model, dir_path + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
