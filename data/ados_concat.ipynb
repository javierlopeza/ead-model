{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "from itertools import combinations\n",
    "\n",
    "def get_filenames(path, exclude=[]):\n",
    "    \"\"\"\n",
    "    Returns list of datasets filenames in path\n",
    "    \"\"\"\n",
    "    directory = \"ados_datasets_all/\"\n",
    "    exclude = []\n",
    "    files = [join(directory, f) for f in listdir(directory) \\\n",
    "             if isfile(join(directory, f)) \\\n",
    "             and f.startswith(\"ados\") and f.endswith(\".txt\") and f not in exclude]\n",
    "    return files\n",
    "\n",
    "def delete_nan_columns(df, max_nan_ratio):\n",
    "    \"\"\"\n",
    "    Delete columns from df with more than max_nan_ratio of NaN values\n",
    "    \"\"\"\n",
    "    for col in sorted(df.columns):\n",
    "        count_nan = df[col].isnull().sum()\n",
    "        ratio_nan = count_nan / len(df)\n",
    "        if ratio_nan > max_nan_ratio:\n",
    "            del df[col]\n",
    "            \n",
    "def has_required_columns(df, required_columns):\n",
    "    \"\"\"\n",
    "    Check if df has required_columns\n",
    "    \"\"\"\n",
    "    return set(required_columns) < set(df.columns)\n",
    "\n",
    "def remove_preffix(df, col):\n",
    "    \"\"\"\n",
    "    Handles appearances of preffixes in columns names\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\"^[a-eA-E]{1}[0-9]{1,2}[aA]?\\.\")\n",
    "    match = pattern.match(col)\n",
    "    if match:\n",
    "        clean_col = col[match.span()[1]:].strip()\n",
    "        if clean_col.lower() in map(str.lower, df.columns):\n",
    "            del df[col]\n",
    "        else:\n",
    "            df.rename(columns = {col : clean_col}, inplace=True)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_suffix(df, col):\n",
    "    \"\"\"\n",
    "    Handles appearances of suffixes in columns names\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\".*\\.[1-9]$\")\n",
    "    match = pattern.match(col)\n",
    "    if match:\n",
    "        if col[:-2] in df:\n",
    "            del df[col]\n",
    "        else:\n",
    "            df.rename(columns = {col : col[:-2]}, inplace=True)\n",
    "            \n",
    "def similarity(a, b):\n",
    "    \"\"\"\n",
    "    Returns similarity ratio between strings a and b\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def generate_similar_names(df, min_similarity=0.9):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of similar names within df.columns\n",
    "    \"\"\"\n",
    "    return {c1: c2 for (c1, c2) in combinations(df.columns, 2) if similarity(c1, c2) > min_similarity}\n",
    "            \n",
    "def merge_similar_columns(df, similar_names):\n",
    "    \"\"\"\n",
    "    Merges columns with similar names, using the non-NaN values if possible\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col in similar_names:\n",
    "            # Combine both columns into the first one\n",
    "            df[col] = df[col].fillna(df[similar_names[col]])\n",
    "            # Delete the second column\n",
    "            del df[similar_names[col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file: ados_datasets_all/ados3_201201.txt\n",
      "Adding file: ados_datasets_all/ados2_200102.txt\n",
      "Adding file: ados_datasets_all/ados4_201201.txt\n",
      "Adding file: ados_datasets_all/ados1_201201.txt\n",
      "Adding file: ados_datasets_all/ados2_200701.txt\n",
      "Adding file: ados_datasets_all/ados2_201201.txt\n",
      "Adding file: ados_datasets_all/ados4_200102.txt\n",
      "Adding file: ados_datasets_all/ados1_200701.txt\n",
      "Adding file: ados_datasets_all/ados1_200102.txt\n",
      "Adding file: ados_datasets_all/ados3_200701.txt\n",
      "Adding file: ados_datasets_all/ados3_200102.txt\n",
      "\n",
      "SIMILAR NAMES: {\n",
      " \"amount of social overtures/maintenance of attention\": \"amount of social overtures/maintenance of attention: examiner\",\n",
      " \"descriptive, conventional, instrumental or informational gestures\": \"descriptive, conventional, instrumental, or informational gestures\",\n",
      " \"overall level of non-echoed language\": \"overall level of non-echoed spoken language\"\n",
      "}\n",
      "\n",
      "COLUMNS:\n",
      "ados diagnosis classification\n",
      "age in months at the time of the interview/test/sampling/imaging.\n",
      "anxiety\n",
      "collection_id\n",
      "collection_title\n",
      "dataset_id\n",
      "date on which the interview/genetic test/sampling/imaging/biospecimen was completed. mm/dd/yyyy\n",
      "hand and finger and other complex mannerisms\n",
      "imagination/creativity\n",
      "immediate echolalia\n",
      "overall ados diagnosis\n",
      "promoted_subjectkey\n",
      "quality of social overtures\n",
      "self-injurious behavior\n",
      "sex of the subject\n",
      "shared enjoyment in interaction\n",
      "stereotyped/idiosyncratic use of words or phrases\n",
      "subject id how it's defined in lab/project\n",
      "tantrums, aggression, negative or disruptive behavior\n",
      "the ndar global unique identifier (guid) for research subject\n",
      "unusual eye contact\n",
      "\n",
      "TOTAL COLUMNS: 21\n",
      "\n",
      "Number of rows with...\n",
      "\t... 0 NaN features: 15893\n",
      "\t... 1 NaN features: 1965\n",
      "\t... 2 NaN features: 357\n",
      "\t... 3 NaN features: 465\n",
      "\t... 4 NaN features: 617\n",
      "\t... 5 NaN features: 50\n",
      "\t... 6 NaN features: 120\n",
      "\t... 7 NaN features: 2\n",
      "\t... 8 NaN features: 126\n",
      "\t... 9 NaN features: 20\n",
      "\t... 10 NaN features: 1877\n",
      "\t... 11 NaN features: 282\n",
      "\t... 12 NaN features: 26\n",
      "\t... 13 NaN features: 48\n",
      "\t... 14 NaN features: 3\n",
      "\t... 15 NaN features: 0\n",
      "\t... 16 NaN features: 0\n",
      "\t... 17 NaN features: 0\n",
      "\t... 18 NaN features: 0\n",
      "\t... 19 NaN features: 0\n",
      "\t... 20 NaN features: 0\n",
      "\t... 21 NaN features: 0\n",
      "\n",
      "TOTAL ROWS: 21851\n"
     ]
    }
   ],
   "source": [
    "files = get_filenames(\"ados_datasets_all/\")\n",
    "    \n",
    "required_columns = [\n",
    "    \"ADOS Diagnosis Classification\"\n",
    "]\n",
    "\n",
    "concat_df = pd.DataFrame()  # Concatenation of clean dataframes\n",
    "for f in files:\n",
    "    df = pd.read_table(f, header=1, sep=\"\\t\")  # Read dataset using 2nd row values as columns headers\n",
    "    \n",
    "    \"\"\"\n",
    "    if not has_required_columns(df, required_columns):\n",
    "        continue\n",
    "    \"\"\"\n",
    "    # Delete columns with more than 80% of NaN values\n",
    "    delete_nan_columns(concat_df, max_nan_ratio=0.80)\n",
    "    \n",
    "    # Remove duplicate columns (just keep one of them)\n",
    "    lower_columns = [x.lower() for x in df.columns]\n",
    "    for col in sorted(df.columns):\n",
    "        # Check for columns ending with \".1\" or \".2\" or ...\n",
    "        remove_suffix(df, col)\n",
    "                \n",
    "        # Remove duplicated columns\n",
    "        if lower_columns.count(col.lower()) > 1:\n",
    "            del df[col]\n",
    "            \n",
    "        # Check for columns starting with a \"A12.a\" pattern and rename them\n",
    "        remove_preffix(df, col)\n",
    "        \n",
    "    # Transform columns names to lowercase\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    # Concatenate dataframes\n",
    "    if concat_df.empty:\n",
    "        concat_df = df\n",
    "    else:\n",
    "        concat_df = pd.concat([concat_df, df], join=\"outer\", ignore_index=True)\n",
    "    \n",
    "    print(\"Adding file: {}\".format(f))\n",
    "\n",
    "# Generate similar names dictionary\n",
    "similar_names = generate_similar_names(concat_df)\n",
    "print(\"\\nSIMILAR NAMES:\", json.dumps(similar_names, indent=1))\n",
    "\n",
    "# Add special cases (not similar names, but corresponding columns)\n",
    "# TODO\n",
    "    \n",
    "# Merge columns with similar names\n",
    "merge_similar_columns(concat_df, similar_names)\n",
    "\n",
    "# Delete columns with more than 25% of NaN values\n",
    "delete_nan_columns(concat_df, 0.25)\n",
    "    \n",
    "# Stats\n",
    "print(\"\\nCOLUMNS:\")\n",
    "for col in sorted(concat_df.columns):\n",
    "    print(col)\n",
    "print(\"\\nTOTAL COLUMNS:\", len(concat_df.columns))\n",
    "    \n",
    "concat_df\n",
    "print(\"\\nNumber of rows with...\")\n",
    "for i in range(len(concat_df.columns) + 1):\n",
    "    non_nan_rows = np.sum(concat_df.isnull().sum(axis=1) == i)\n",
    "    print(\"\\t... {} NaN features: {}\".format(i, non_nan_rows))\n",
    "print(\"\\nTOTAL ROWS:\", len(concat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# come up\n",
    "# -1: unknonw\n",
    "# 0: non sepctrum\n",
    "# 1: Autism Spectrum \n",
    "# 2: autism\n",
    "\n",
    "def updateDiagnosis(diagnosis):\n",
    "    if diagnosis in [0,1,2,3,'2']:\n",
    "        return 0\n",
    "    if diagnosis in [4,5]:\n",
    "        return 1\n",
    "    if diagnosis in [i for i in range(6,11)] + [str(i) for i in range(6,11)]:\n",
    "        return 2\n",
    "    new = str.lower(str(diagnosis))\n",
    "    new = re.sub('[- ./]', '', new)\n",
    "    if '?' in new or 'nan' in new or 'dd' in new or 'unknown' in new:\n",
    "        return -1\n",
    "    if 'non' in new or 'not' in new or 'typical' in new:\n",
    "        return 0\n",
    "    if 'spectrum' in new:\n",
    "        return 1\n",
    "    if 'aut' in new or 'asd' in new:\n",
    "        return 2\n",
    "    return new\n",
    "    \n",
    "concat_df['diagnosis'] = concat_df['ados diagnosis classification'].apply(updateDiagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "concat_df.to_csv('ados_datasets_all/current_data.txt', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ados diagnosis classification                                                                       701\n",
       "age in months at the time of the interview/test/sampling/imaging.                                   512\n",
       "anxiety                                                                                            2463\n",
       "collection_id                                                                                         0\n",
       "collection_title                                                                                      0\n",
       "dataset_id                                                                                            0\n",
       "date on which the interview/genetic test/sampling/imaging/biospecimen was completed. mm/dd/yyyy     367\n",
       "hand and finger and other complex mannerisms                                                       2739\n",
       "imagination/creativity                                                                             2366\n",
       "immediate echolalia                                                                                2472\n",
       "overall ados diagnosis                                                                             1843\n",
       "promoted_subjectkey                                                                                   0\n",
       "quality of social overtures                                                                        2731\n",
       "self-injurious behavior                                                                            2554\n",
       "sex of the subject                                                                                  393\n",
       "shared enjoyment in interaction                                                                    2904\n",
       "stereotyped/idiosyncratic use of words or phrases                                                  4329\n",
       "subject id how it's defined in lab/project                                                            0\n",
       "tantrums, aggression, negative or disruptive behavior                                              2460\n",
       "the ndar global unique identifier (guid) for research subject                                         0\n",
       "unusual eye contact                                                                                2730\n",
       "diagnosis                                                                                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2                           9259\n",
       "0                           5440\n",
       "999                         2272\n",
       "1                           1273\n",
       "1                           1249\n",
       "-1                          1033\n",
       "0                            669\n",
       "3                            172\n",
       "nodiagnosis                  170\n",
       "classified                    80\n",
       "healthycontrol                68\n",
       "nodx                          47\n",
       "code                          32\n",
       "na                            28\n",
       "ad                            10\n",
       "99                             6\n",
       "au                             5\n",
       "blankonform                    5\n",
       "minimaltonoevidence            4\n",
       "moderate                       4\n",
       "aspergers                      3\n",
       "25                             2\n",
       "5                              2\n",
       "metcriteriafordx               2\n",
       "fuwithadi                      2\n",
       "mintonoevidence                2\n",
       "minimaltonoevidence(low)       2\n",
       "asperger's                     1\n",
       "low(3)                         1\n",
       "19                             1\n",
       "no_diagnosis                   1\n",
       "                               1\n",
       "module6                        1\n",
       "12                             1\n",
       "module5                        1\n",
       "ns                             1\n",
       "module4                        1\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21851, 22)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
