{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "from itertools import combinations\n",
    "\n",
    "def get_filenames(path, exclude=[]):\n",
    "    \"\"\"\n",
    "    Returns list of datasets filenames in path\n",
    "    \"\"\"\n",
    "    directory = \"ados_datasets/\"\n",
    "    exclude = []\n",
    "    files = [join(directory, f) for f in listdir(directory) \\\n",
    "             if isfile(join(directory, f)) \\\n",
    "             and f.startswith(\"ados\") and f.endswith(\".txt\") and f not in exclude]\n",
    "    return files\n",
    "\n",
    "def delete_nan_columns(df, max_nan_ratio):\n",
    "    \"\"\"\n",
    "    Delete columns from df with more than max_nan_ratio of NaN values\n",
    "    \"\"\"\n",
    "    for col in sorted(df.columns):\n",
    "        count_nan = df[col].isnull().sum()\n",
    "        ratio_nan = count_nan / len(df)\n",
    "        if ratio_nan > max_nan_ratio:\n",
    "            del df[col]\n",
    "            \n",
    "def has_required_columns(df, required_columns):\n",
    "    \"\"\"\n",
    "    Check if df has required_columns\n",
    "    \"\"\"\n",
    "    return set(required_columns) < set(df.columns)\n",
    "\n",
    "def remove_preffix(df, col):\n",
    "    \"\"\"\n",
    "    Handles appearances of preffixes in columns names\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\"^[a-eA-E]{1}[0-9]{1,2}[aA]?\\.\")\n",
    "    match = pattern.match(col)\n",
    "    if match:\n",
    "        clean_col = col[match.span()[1]:].strip()\n",
    "        if clean_col.lower() in map(str.lower, df.columns):\n",
    "            del df[col]\n",
    "        else:\n",
    "            df.rename(columns = {col : clean_col}, inplace=True)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def remove_suffix(df, col):\n",
    "    \"\"\"\n",
    "    Handles appearances of suffixes in columns names\n",
    "    \"\"\"\n",
    "    pattern = re.compile(\".*\\.[1-9]$\")\n",
    "    match = pattern.match(col)\n",
    "    if match:\n",
    "        if col[:-2] in df:\n",
    "            del df[col]\n",
    "        else:\n",
    "            df.rename(columns = {col : col[:-2]}, inplace=True)\n",
    "            \n",
    "def similarity(a, b):\n",
    "    \"\"\"\n",
    "    Returns similarity ratio between strings a and b\n",
    "    \"\"\"\n",
    "    return SequenceMatcher(None, a, b).ratio()\n",
    "\n",
    "def generate_similar_names(df, min_similarity=0.9):\n",
    "    \"\"\"\n",
    "    Returns a dictionary of similar names within df.columns\n",
    "    \"\"\"\n",
    "    return {c1: c2 for (c1, c2) in combinations(df.columns, 2) if similarity(c1, c2) > min_similarity}\n",
    "            \n",
    "def merge_similar_columns(df, similar_names):\n",
    "    \"\"\"\n",
    "    Merges columns with similar names, using the non-NaN values if possible\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if col in similar_names:\n",
    "            # Combine both columns into the first one\n",
    "            df[col] = df[col].fillna(df[similar_names[col]])\n",
    "            # Delete the second column\n",
    "            del df[similar_names[col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding file: ados_datasets/ados1_200102.txt\n",
      "Adding file: ados_datasets/ados1_200102_1250.txt\n",
      "Adding file: ados_datasets/ados1_200102_19.txt\n",
      "Adding file: ados_datasets/ados1_200102_2382.txt\n",
      "Adding file: ados_datasets/ados1_200102_9.txt\n",
      "Adding file: ados_datasets/ados1_200701_1250.txt\n",
      "Adding file: ados_datasets/ados1_200701_1946.txt\n",
      "Adding file: ados_datasets/ados1_201201_1250.txt\n",
      "Adding file: ados_datasets/ados1_201201_19.txt\n",
      "Adding file: ados_datasets/ados1_201201_1946.txt\n",
      "Adding file: ados_datasets/ados1_201201_2080.txt\n",
      "Adding file: ados_datasets/ados1_201201_2368.txt\n",
      "Adding file: ados_datasets/ados2_200102.txt\n",
      "Adding file: ados_datasets/ados2_200102_1250.txt\n",
      "Adding file: ados_datasets/ados2_200102_2382.txt\n",
      "Adding file: ados_datasets/ados2_200102_9.txt\n",
      "Adding file: ados_datasets/ados2_200701_1250.txt\n",
      "Adding file: ados_datasets/ados2_200701_1946.txt\n",
      "Adding file: ados_datasets/ados2_201201_1250.txt\n",
      "Adding file: ados_datasets/ados2_201201_19.txt\n",
      "Adding file: ados_datasets/ados2_201201_1946.txt\n",
      "Adding file: ados_datasets/ados2_201201_2080.txt\n",
      "Adding file: ados_datasets/ados2_201201_2368.txt\n",
      "Adding file: ados_datasets/ados3_200102_1250.txt\n",
      "Adding file: ados_datasets/ados3_200102_2382.txt\n",
      "Adding file: ados_datasets/ados3_201201_1946.txt\n",
      "Adding file: ados_datasets/ados3_201201_2080.txt\n",
      "Adding file: ados_datasets/ados3_201201_2368.txt\n",
      "Adding file: ados_datasets/ados4_200102_2382.txt\n",
      "\n",
      "SIMILAR NAMES: {\n",
      " \"descriptive, conventional, instrumental or informational gestures\": \"descriptive, conventional, instrumental, or informational gestures\"\n",
      "}\n",
      "\n",
      "COLUMNS:\n",
      "ados diagnosis classification\n",
      "age in months at the time of the interview/test/sampling/imaging.\n",
      "anxiety\n",
      "collection_id\n",
      "collection_title\n",
      "dataset_id\n",
      "date on which the interview/genetic test/sampling/imaging/biospecimen was completed. mm/dd/yyyy\n",
      "hand and finger and other complex mannerisms\n",
      "imagination/creativity\n",
      "immediate echolalia\n",
      "overall ados diagnosis\n",
      "promoted_subjectkey\n",
      "quality of social overtures\n",
      "self-injurious behavior\n",
      "sex of the subject\n",
      "shared enjoyment in interaction\n",
      "subject id how it's defined in lab/project\n",
      "tantrums, aggression, negative or disruptive behavior\n",
      "the ndar global unique identifier (guid) for research subject\n",
      "unusual eye contact\n",
      "\n",
      "TOTAL COLUMNS: 20\n",
      "\n",
      "Number of rows with...\n",
      "\t... 0 NaN features: 2733\n",
      "\t... 1 NaN features: 331\n",
      "\t... 2 NaN features: 3\n",
      "\t... 3 NaN features: 19\n",
      "\t... 4 NaN features: 9\n",
      "\t... 5 NaN features: 0\n",
      "\t... 6 NaN features: 0\n",
      "\t... 7 NaN features: 0\n",
      "\t... 8 NaN features: 2\n",
      "\t... 9 NaN features: 911\n",
      "\t... 10 NaN features: 0\n",
      "\t... 11 NaN features: 0\n",
      "\t... 12 NaN features: 64\n",
      "\t... 13 NaN features: 0\n",
      "\t... 14 NaN features: 0\n",
      "\t... 15 NaN features: 0\n",
      "\t... 16 NaN features: 0\n",
      "\t... 17 NaN features: 0\n",
      "\t... 18 NaN features: 0\n",
      "\t... 19 NaN features: 0\n",
      "\t... 20 NaN features: 0\n",
      "\n",
      "TOTAL ROWS: 4072\n"
     ]
    }
   ],
   "source": [
    "files = get_filenames(\"ados_datasets/\")\n",
    "    \n",
    "required_columns = [\n",
    "    \"ADOS Diagnosis Classification\"\n",
    "]\n",
    "\n",
    "concat_df = pd.DataFrame()  # Concatenation of clean dataframes\n",
    "for f in files:\n",
    "    df = pd.read_table(f, header=1, sep=\"\\t\")  # Read dataset using 2nd row values as columns headers\n",
    "    \n",
    "    \"\"\"\n",
    "    if not has_required_columns(df, required_columns):\n",
    "        continue\n",
    "    \"\"\"\n",
    "    # Delete columns with more than 80% of NaN values\n",
    "    delete_nan_columns(concat_df, max_nan_ratio=0.80)\n",
    "    \n",
    "    # Remove duplicate columns (just keep one of them)\n",
    "    lower_columns = [x.lower() for x in df.columns]\n",
    "    for col in sorted(df.columns):\n",
    "        # Check for columns ending with \".1\" or \".2\" or ...\n",
    "        remove_suffix(df, col)\n",
    "                \n",
    "        # Remove duplicated columns\n",
    "        if lower_columns.count(col.lower()) > 1:\n",
    "            del df[col]\n",
    "            \n",
    "        # Check for columns starting with a \"A12.a\" pattern and rename them\n",
    "        remove_preffix(df, col)\n",
    "        \n",
    "    # Transform columns names to lowercase\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    \n",
    "    # Concatenate dataframes\n",
    "    if concat_df.empty:\n",
    "        concat_df = df\n",
    "    else:\n",
    "        concat_df = pd.concat([concat_df, df], join=\"outer\", ignore_index=True)\n",
    "    \n",
    "    print(\"Adding file: {}\".format(f))\n",
    "\n",
    "# Generate similar names dictionary\n",
    "similar_names = generate_similar_names(concat_df)\n",
    "print(\"\\nSIMILAR NAMES:\", json.dumps(similar_names, indent=1))\n",
    "\n",
    "# Add special cases (not similar names, but corresponding columns)\n",
    "# TODO\n",
    "    \n",
    "# Merge columns with similar names\n",
    "merge_similar_columns(concat_df, similar_names)\n",
    "\n",
    "# Delete columns with more than 25% of NaN values\n",
    "delete_nan_columns(concat_df, 0.25)\n",
    "    \n",
    "# Stats\n",
    "print(\"\\nCOLUMNS:\")\n",
    "for col in sorted(concat_df.columns):\n",
    "    print(col)\n",
    "print(\"\\nTOTAL COLUMNS:\", len(concat_df.columns))\n",
    "    \n",
    "concat_df\n",
    "print(\"\\nNumber of rows with...\")\n",
    "for i in range(len(concat_df.columns) + 1):\n",
    "    non_nan_rows = np.sum(concat_df.isnull().sum(axis=1) == i)\n",
    "    print(\"\\t... {} NaN features: {}\".format(i, non_nan_rows))\n",
    "print(\"\\nTOTAL ROWS:\", len(concat_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# come up\n",
    "# -1: unknonw\n",
    "# 0: non sepctrum\n",
    "# 1: Autism Spectrum \n",
    "# 2: autism\n",
    "\n",
    "def updateDiagnosis(diagnosis):\n",
    "    if diagnosis in [0,1,2,3,'2']:\n",
    "        return 0\n",
    "    if diagnosis in [4,5]:\n",
    "        return 1\n",
    "    if diagnosis in [i for i in range(6,11)] + [str(i) for i in range(6,11)]:\n",
    "        return 2\n",
    "    new = str.lower(str(diagnosis))\n",
    "    new = re.sub('[- ./]', '', new)\n",
    "    if '?' in new or 'nan' in new or 'dd' in new or 'unknown' in new:\n",
    "        return -1\n",
    "    if 'non' in new or 'not' in new or 'typical' in new:\n",
    "        return 0\n",
    "    if 'spectrum' in new:\n",
    "        return 1\n",
    "    if 'aut' in new or 'asd' in new:\n",
    "        return 2\n",
    "    return new\n",
    "    \n",
    "concat_df['diagnosis'] = concat_df['ados diagnosis classification'].apply(updateDiagnosis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_df.to_csv('ados_datasets/current_data.txt', sep='\\t', mode='a', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ados diagnosis classification                                                                        83\n",
       "age in months at the time of the interview/test/sampling/imaging.                                     0\n",
       "anxiety                                                                                            1009\n",
       "collection_id                                                                                         0\n",
       "collection_title                                                                                      0\n",
       "dataset_id                                                                                            0\n",
       "date on which the interview/genetic test/sampling/imaging/biospecimen was completed. mm/dd/yyyy       0\n",
       "hand and finger and other complex mannerisms                                                        986\n",
       "imagination/creativity                                                                              975\n",
       "immediate echolalia                                                                                 977\n",
       "overall ados diagnosis                                                                              357\n",
       "promoted_subjectkey                                                                                   0\n",
       "quality of social overtures                                                                         977\n",
       "self-injurious behavior                                                                             986\n",
       "sex of the subject                                                                                  119\n",
       "shared enjoyment in interaction                                                                     977\n",
       "subject id how it's defined in lab/project                                                            0\n",
       "tantrums, aggression, negative or disruptive behavior                                               990\n",
       "the ndar global unique identifier (guid) for research subject                                         0\n",
       "unusual eye contact                                                                                 977\n",
       "diagnosis                                                                                             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    2161\n",
       " 2    1399\n",
       " 1     338\n",
       "-1     174\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df['diagnosis'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4072, 21)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concat_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
